{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stuck-people",
   "metadata": {},
   "source": [
    "# \"Working with Text Data\"\n",
    "\n",
    "**Author:** 'Felipe Millacura'\n",
    "    \n",
    "**Date:** '28th February 2021'\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "\n",
    "* Know how to convert from text data to tokenised text data using `unnest_tokens`.\n",
    "* Understand how text data can be cleaned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-sense",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "We've worked with small amounts of text data before; anything that is an `object` variable in our dataset counts as text data. But how do you work with a large chunk of text like a set of articles, or a book?\n",
    "\n",
    "In this lesson we'll learn how you can turn text into a format that is useful, in particular how to turn text into a data frame. We'll do this using the `tidytext` package.\n",
    "\n",
    "\n",
    "Also you will learn about `TF-IDF scores`, `n-grams` and how to find the sentiment of words and of texts as a whole. Sentiment is the feelings demonstrated in the text, this can be as simple as positive/negative, or include emotions like fear, disgust and joy. \n",
    "\n",
    "Sentiment analysis is not an exact science! The results you get may not make scene in context, hence, you should always treat any sentiment analysis with some scepticism.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-report",
   "metadata": {},
   "source": [
    "## Un-nesting tokens\n",
    "\n",
    "### The `unnest_tokens` function\n",
    "\n",
    "To start we need to install the `tidytext` package. This package helps us transform text into *tidy* data; that is data where each variable is a column and each observation a row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "growing-holiday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tidytext in c:\\users\\fmill\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: siuba in c:\\users\\fmill\\anaconda3\\lib\\site-packages (from tidytext) (0.0.24)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\fmill\\anaconda3\\lib\\site-packages (from siuba->tidytext) (1.19.5)\n",
      "Requirement already satisfied: PyYAML>=3.0.0 in c:\\users\\fmill\\anaconda3\\lib\\site-packages (from siuba->tidytext) (5.3.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.1.18 in c:\\users\\fmill\\anaconda3\\lib\\site-packages (from siuba->tidytext) (1.3.21)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\fmill\\anaconda3\\lib\\site-packages (from siuba->tidytext) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\fmill\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->siuba->tidytext) (2020.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\fmill\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->siuba->tidytext) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fmill\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->siuba->tidytext) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tidytext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-preference",
   "metadata": {},
   "source": [
    "This will also install the `nltk` package. However, you will need to download additional resources to use tidytext, using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "least-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "secret-document",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\fmill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-gilbert",
   "metadata": {},
   "source": [
    "Now we are ready to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sharp-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-recall",
   "metadata": {},
   "source": [
    "Here's an example of very simple text data - just a three element object. Don't worry we'll be working with more complicated, realistic data soon!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "reported-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = [\"here is some text\",\n",
    "           \"again more text\",\n",
    "           \"text is text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-pillow",
   "metadata": {},
   "source": [
    "We need this text to be in a `DataFrame` before we can start using `tidytext`. In this case each element of the vector will be associated with an ID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "future-stuart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>here is some text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>again more text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text is text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              phrase\n",
       "0  here is some text\n",
       "1    again more text\n",
       "2       text is text"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = pd.DataFrame({\n",
    "     'phrase' : phrases\n",
    "    \n",
    "})\n",
    "\n",
    "example_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-biodiversity",
   "metadata": {},
   "source": [
    "Now that our data is inside a data frame we can use the `unnest_tokens` function from `tidytext` to transform this data.\n",
    "\n",
    "The `unnest_tokens` function is probably the most important function in tidytext. It takes data from a an `object` variable (aka `string`) and splits it into *tokens*. For just now, the tokens will be words, but it's also possible to specify that our tokens are sentences, or characters. We'll see the options for different tokens later.\n",
    "\n",
    "The `unnest_tokens` function takes three mandatory arguments. The first is the data frame that contains our text data; here we have piped that in. The second is the new column that we are going to create that contains our tokens, in our case we've called it `word` because the tokens are words. And the third argument is the name of the column that contains the text data that we are going to tokenise, in our case `phrase`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "universal-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tidytext import unnest_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "expressed-device",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>some</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word\n",
       "0   here\n",
       "0     is\n",
       "0   some\n",
       "0   text\n",
       "1  again\n",
       "1   more\n",
       "1   text\n",
       "2   text\n",
       "2     is\n",
       "2   text"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df = unnest_tokens(example_text, 'word', 'phrase')\n",
    "\n",
    "words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-reliance",
   "metadata": {},
   "source": [
    "You'll notice that the ID column has been preserved. You can go and check that all the words that appeared in the first phrase have id 0, all the words that appeared in the second phrase have id 1 etc. This is really useful when we have extra information about the text in our original data that we want to preserve through tokenisation.\n",
    "\n",
    "Now that we have a tidy data frame, it's easy to manipulate using `pandas`. To start, let's put our words in alphabetical order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "enhanced-transfer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>some</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word\n",
       "1  again\n",
       "0   here\n",
       "0     is\n",
       "2     is\n",
       "1   more\n",
       "0   some\n",
       "0   text\n",
       "1   text\n",
       "2   text\n",
       "2   text"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.sort_values('word')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-designer",
   "metadata": {},
   "source": [
    "A really common task that you'll want to perform is finding out how often each word appears in each phrase. We can do this with a `groupby` and `size`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "roman-johns",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>level_1</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>again</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>here</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>more</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>some</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>text</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>text</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>text</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  level_1  counts\n",
       "0  again        1       1\n",
       "1   here        0       1\n",
       "2     is        0       1\n",
       "3     is        2       1\n",
       "4   more        1       1\n",
       "5   some        0       1\n",
       "6   text        0       1\n",
       "7   text        1       1\n",
       "8   text        2       2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.groupby(['word', words_df.index]).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-botswana",
   "metadata": {},
   "source": [
    "Or you may want to count the words across all phrases. Again, this is done with group by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "greek-popularity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>again</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>here</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>some</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>text</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  counts\n",
       "0  again       1\n",
       "1   here       1\n",
       "2     is       2\n",
       "3   more       1\n",
       "4   some       1\n",
       "5   text       4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.groupby('word').size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-intelligence",
   "metadata": {},
   "source": [
    "With only a small amount of code we can see that the most common word in our phrases was 'text' and it appears 4 times.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-inclusion",
   "metadata": {},
   "source": [
    "### Capitals and punctuation\n",
    "\n",
    "Here's an example of another small text dataset. Before you run the code below, have a think about the data frame you will produce.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "manufactured-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = [\"Here is some text.\",\n",
    "           \"Again, more text!\",\n",
    "           \"TEXT is text?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "wireless-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = pd.DataFrame({\n",
    "    'phrase' : phrases,\n",
    "    'id'     : range(1,4)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "derived-cradle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here is some text.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Again, more text!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEXT is text?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               phrase  id\n",
       "0  Here is some text.   1\n",
       "1   Again, more text!   2\n",
       "2       TEXT is text?   3"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "latin-benjamin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>some</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   word\n",
       "0   1   here\n",
       "0   1     is\n",
       "0   1   some\n",
       "0   1   text\n",
       "1   2  again\n",
       "1   2   more\n",
       "1   2   text\n",
       "2   3   text\n",
       "2   3     is\n",
       "2   3   text"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unnest_tokens(example_text, 'word', 'phrase')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-surveillance",
   "metadata": {},
   "source": [
    "Is this what you were expecting? Probably not, by default `tidytext` converts all text to lower case before tokenising into words. It also ignores punctuation.\n",
    "\n",
    "This is *normally* a good thing: most times when you are analysing text, you don't care about the difference between \"Text\", \"TEXT,\" and \"text\". You just want to know how often the word text appears in the data in any context.\n",
    "\n",
    "However, if you do care about different capitalisations you can set `to_lower` to be `FALSE` inside `unnest_tokens`. You cannot currently choose to not strip punctuation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "developmental-twist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>some</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>TEXT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   word\n",
       "0   1   Here\n",
       "0   1     is\n",
       "0   1   some\n",
       "0   1   text\n",
       "1   2  Again\n",
       "1   2   more\n",
       "1   2   text\n",
       "2   3   TEXT\n",
       "2   3     is\n",
       "2   3   text"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df = unnest_tokens(example_text, 'word', 'phrase',  to_lower= False)\n",
    "\n",
    "words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-master",
   "metadata": {},
   "source": [
    "Again, let's find out how often each word appears and arrange from the most common word to the least common.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "scheduled-drink",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Again</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Here</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEXT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>more</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>some</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  counts\n",
       "0   text       3\n",
       "1     is       2\n",
       "2  Again       1\n",
       "3   Here       1\n",
       "4   TEXT       1\n",
       "5   more       1\n",
       "6   some       1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.groupby('word').size().sort_values(ascending=False).reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-stomach",
   "metadata": {},
   "source": [
    "Since this is such a common pattern (not just in text mining, but in many types of analysis) `pandas` provides a short-cut. The function `value_counts` will group by the variable or variables given, and summarise by `count`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "useful-feeling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Again</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Here</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEXT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>more</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>some</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  counts\n",
       "0   text       3\n",
       "1     is       2\n",
       "2  Again       1\n",
       "3   Here       1\n",
       "4   TEXT       1\n",
       "5   more       1\n",
       "6   some       1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.value_counts('word').reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-sunglasses",
   "metadata": {},
   "source": [
    "You can even set `sort = False` to stop the final arranging step too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "reverse-mambo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Again</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Here</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEXT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>more</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>some</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>text</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  counts\n",
       "0  Again       1\n",
       "1   Here       1\n",
       "2   TEXT       1\n",
       "3     is       2\n",
       "4   more       1\n",
       "5   some       1\n",
       "6   text       3"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.value_counts('word', sort=False).reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-arabic",
   "metadata": {},
   "source": [
    "In the rest of these notes we will be using the shortcut version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "appropriate-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [\n",
    "  \"Whose woods these are I think I know.\",\n",
    "  \"His house is in the village though;\", \n",
    "  \"He will not see me stopping here\",\n",
    "  \"To watch his woods fill up with snow.\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-marketing",
   "metadata": {},
   "source": [
    "1. Create a data frame that has two variables: one with each word, the second with the line number of the word.\n",
    "2. Use this data frame to find all the words that appear more than once in the four lines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-european",
   "metadata": {},
   "source": [
    "## Removing stop words\n",
    "\n",
    "As promised, let's look at a more realistic text dataset. For this we'll use the text for all seven `Harry Potter` books. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "quantitative-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "philosophers_stone = pd.read_csv(\"data/HPBook1.txt\",  sep=\"@\")\n",
    "chamber_of_secrets = pd.read_csv(\"data/HPBook2.txt\",  sep=\"@\")\n",
    "prisoner_of_azkaban = pd.read_csv(\"data/HPBook3.txt\",  sep=\"@\")\n",
    "goblet_of_fire = pd.read_csv(\"data/HPBook4.txt\",  sep=\"@\")\n",
    "order_of_the_phoenix = pd.read_csv(\"data/HPBook5.txt\",  sep=\"@\")\n",
    "half_blood_prince = pd.read_csv(\"data/HPBook6.txt\",  sep=\"@\")\n",
    "deathly_hallows = pd.read_csv(\"data/HPBook7.txt\",  sep=\"@\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-developer",
   "metadata": {},
   "source": [
    "Each book is stored as its own `DataFrame` and each chapter as an `object` variable, where each element contains all the text in one chapter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "stone-circumstances",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE BOY WHO LIVED  Mr. and Mrs. Dursley, of nu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THE VANISHING GLASS  Nearly ten years had pass...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THE LETTERS FROM NO ONE  The escape of the Bra...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE KEEPER OF THE KEYS  BOOM. They knocked aga...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DIAGON ALLEY  Harry woke early the next mornin...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>THE JOURNEY FROM PLATFORM NINE AND THREE-QUART...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>THE SORTING HAT  The door swung open at once. ...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>THE POTIONS MASTER  There, look.\\  \\\"Where?\\\" ...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>THE MIDNIGHT DUEL  Harry had never believed he...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HALLOWEEN  Malfoy couldn't believe his eyes wh...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>QUIDDITCH  As they entered November, the weath...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>THE MIRROR OF ERISED  Christmas was coming. On...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NICOLAS FLAMEL  Dumbledore had convinced Harry...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NORBERT THE NORWEGIAN RIDGEBACK  Quirrell, how...</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>THE FORIBIDDEN FOREST  Things couldn't have be...</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>THROUGH THE TRAPDOOR  In years to come, Harry ...</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>THE MAN WITH TWO FACES  It was Quirrell.  \\You...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  Chapter  Book\n",
       "0   THE BOY WHO LIVED  Mr. and Mrs. Dursley, of nu...        1     1\n",
       "1   THE VANISHING GLASS  Nearly ten years had pass...        2     1\n",
       "2   THE LETTERS FROM NO ONE  The escape of the Bra...        3     1\n",
       "3   THE KEEPER OF THE KEYS  BOOM. They knocked aga...        4     1\n",
       "4   DIAGON ALLEY  Harry woke early the next mornin...        5     1\n",
       "5   THE JOURNEY FROM PLATFORM NINE AND THREE-QUART...        6     1\n",
       "6   THE SORTING HAT  The door swung open at once. ...        7     1\n",
       "7   THE POTIONS MASTER  There, look.\\  \\\"Where?\\\" ...        8     1\n",
       "8   THE MIDNIGHT DUEL  Harry had never believed he...        9     1\n",
       "9   HALLOWEEN  Malfoy couldn't believe his eyes wh...       10     1\n",
       "10  QUIDDITCH  As they entered November, the weath...       11     1\n",
       "11  THE MIRROR OF ERISED  Christmas was coming. On...       12     1\n",
       "12  NICOLAS FLAMEL  Dumbledore had convinced Harry...       13     1\n",
       "13  NORBERT THE NORWEGIAN RIDGEBACK  Quirrell, how...       14     1\n",
       "14  THE FORIBIDDEN FOREST  Things couldn't have be...       15     1\n",
       "15  THROUGH THE TRAPDOOR  In years to come, Harry ...       16     1\n",
       "16  THE MAN WITH TWO FACES  It was Quirrell.  \\You...       17     1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "philosophers_stone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-poster",
   "metadata": {},
   "source": [
    "We can now use `unnest_tokens` to find the most common words in \"The Philosopher's Stone\".\n",
    "\n",
    "What do you notice about the most common words?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "covered-circulation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Book</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>who</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>lived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>dudley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77575 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Chapter  Book    Word\n",
       "0         1     1     the\n",
       "0         1     1     boy\n",
       "0         1     1     who\n",
       "0         1     1   lived\n",
       "0         1     1      mr\n",
       "..      ...   ...     ...\n",
       "16       17     1  dudley\n",
       "16       17     1    this\n",
       "16       17     1  summer\n",
       "16       17     1     the\n",
       "16       17     1     end\n",
       "\n",
       "[77575 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ps = unnest_tokens(philosophers_stone, 'Word', 'Text')\n",
    "\n",
    "df_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "certified-superintendent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word\n",
       "the            3627\n",
       "and            1918\n",
       "to             1856\n",
       "a              1688\n",
       "he             1528\n",
       "               ... \n",
       "scrabbling        1\n",
       "cooked            1\n",
       "forgetmenot       1\n",
       "scraped           1\n",
       "smarmy            1\n",
       "Length: 6034, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ps.value_counts('Word')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-measure",
   "metadata": {},
   "source": [
    "The most common words are not very interesting! They are words common to all English texts.\n",
    "\n",
    "These common English words are known as **stop words**. The [`stop_words`](https://pypi.org/project/stop-words/) library has a built-in data frame that contains stop words in different languages. This means we can remove the stop words from our data by using either  `merge`, `lambda` or `isin`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "pursuant-premium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stop-words in c:\\users\\fmill\\anaconda3\\lib\\site-packages (2018.7.23)\n"
     ]
    }
   ],
   "source": [
    "!pip install stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "rational-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "complex-kruger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'al',\n",
       " 'algo',\n",
       " 'algunas',\n",
       " 'algunos',\n",
       " 'ante',\n",
       " 'antes',\n",
       " 'como',\n",
       " 'con',\n",
       " 'contra',\n",
       " 'cual',\n",
       " 'cuando',\n",
       " 'de',\n",
       " 'del',\n",
       " 'desde',\n",
       " 'donde',\n",
       " 'durante',\n",
       " 'e',\n",
       " 'el',\n",
       " 'ella',\n",
       " 'ellas',\n",
       " 'ellos',\n",
       " 'en',\n",
       " 'entre',\n",
       " 'era',\n",
       " 'erais',\n",
       " 'eran',\n",
       " 'eras',\n",
       " 'eres',\n",
       " 'es',\n",
       " 'esa',\n",
       " 'esas',\n",
       " 'ese',\n",
       " 'eso',\n",
       " 'esos',\n",
       " 'esta',\n",
       " 'estaba',\n",
       " 'estabais',\n",
       " 'estaban',\n",
       " 'estabas',\n",
       " 'estad',\n",
       " 'estada',\n",
       " 'estadas',\n",
       " 'estado',\n",
       " 'estados',\n",
       " 'estamos',\n",
       " 'estando',\n",
       " 'estar',\n",
       " 'estaremos',\n",
       " 'estará',\n",
       " 'estarán',\n",
       " 'estarás',\n",
       " 'estaré',\n",
       " 'estaréis',\n",
       " 'estaría',\n",
       " 'estaríais',\n",
       " 'estaríamos',\n",
       " 'estarían',\n",
       " 'estarías',\n",
       " 'estas',\n",
       " 'este',\n",
       " 'estemos',\n",
       " 'esto',\n",
       " 'estos',\n",
       " 'estoy',\n",
       " 'estuve',\n",
       " 'estuviera',\n",
       " 'estuvierais',\n",
       " 'estuvieran',\n",
       " 'estuvieras',\n",
       " 'estuvieron',\n",
       " 'estuviese',\n",
       " 'estuvieseis',\n",
       " 'estuviesen',\n",
       " 'estuvieses',\n",
       " 'estuvimos',\n",
       " 'estuviste',\n",
       " 'estuvisteis',\n",
       " 'estuviéramos',\n",
       " 'estuviésemos',\n",
       " 'estuvo',\n",
       " 'está',\n",
       " 'estábamos',\n",
       " 'estáis',\n",
       " 'están',\n",
       " 'estás',\n",
       " 'esté',\n",
       " 'estéis',\n",
       " 'estén',\n",
       " 'estés',\n",
       " 'fue',\n",
       " 'fuera',\n",
       " 'fuerais',\n",
       " 'fueran',\n",
       " 'fueras',\n",
       " 'fueron',\n",
       " 'fuese',\n",
       " 'fueseis',\n",
       " 'fuesen',\n",
       " 'fueses',\n",
       " 'fui',\n",
       " 'fuimos',\n",
       " 'fuiste',\n",
       " 'fuisteis',\n",
       " 'fuéramos',\n",
       " 'fuésemos',\n",
       " 'ha',\n",
       " 'habida',\n",
       " 'habidas',\n",
       " 'habido',\n",
       " 'habidos',\n",
       " 'habiendo',\n",
       " 'habremos',\n",
       " 'habrá',\n",
       " 'habrán',\n",
       " 'habrás',\n",
       " 'habré',\n",
       " 'habréis',\n",
       " 'habría',\n",
       " 'habríais',\n",
       " 'habríamos',\n",
       " 'habrían',\n",
       " 'habrías',\n",
       " 'habéis',\n",
       " 'había',\n",
       " 'habíais',\n",
       " 'habíamos',\n",
       " 'habían',\n",
       " 'habías',\n",
       " 'han',\n",
       " 'has',\n",
       " 'hasta',\n",
       " 'hay',\n",
       " 'haya',\n",
       " 'hayamos',\n",
       " 'hayan',\n",
       " 'hayas',\n",
       " 'hayáis',\n",
       " 'he',\n",
       " 'hemos',\n",
       " 'hube',\n",
       " 'hubiera',\n",
       " 'hubierais',\n",
       " 'hubieran',\n",
       " 'hubieras',\n",
       " 'hubieron',\n",
       " 'hubiese',\n",
       " 'hubieseis',\n",
       " 'hubiesen',\n",
       " 'hubieses',\n",
       " 'hubimos',\n",
       " 'hubiste',\n",
       " 'hubisteis',\n",
       " 'hubiéramos',\n",
       " 'hubiésemos',\n",
       " 'hubo',\n",
       " 'la',\n",
       " 'las',\n",
       " 'le',\n",
       " 'les',\n",
       " 'lo',\n",
       " 'los',\n",
       " 'me',\n",
       " 'mi',\n",
       " 'mis',\n",
       " 'mucho',\n",
       " 'muchos',\n",
       " 'muy',\n",
       " 'más',\n",
       " 'mí',\n",
       " 'mía',\n",
       " 'mías',\n",
       " 'mío',\n",
       " 'míos',\n",
       " 'nada',\n",
       " 'ni',\n",
       " 'no',\n",
       " 'nos',\n",
       " 'nosotras',\n",
       " 'nosotros',\n",
       " 'nuestra',\n",
       " 'nuestras',\n",
       " 'nuestro',\n",
       " 'nuestros',\n",
       " 'o',\n",
       " 'os',\n",
       " 'otra',\n",
       " 'otras',\n",
       " 'otro',\n",
       " 'otros',\n",
       " 'para',\n",
       " 'pero',\n",
       " 'poco',\n",
       " 'por',\n",
       " 'porque',\n",
       " 'que',\n",
       " 'quien',\n",
       " 'quienes',\n",
       " 'qué',\n",
       " 'se',\n",
       " 'sea',\n",
       " 'seamos',\n",
       " 'sean',\n",
       " 'seas',\n",
       " 'seremos',\n",
       " 'será',\n",
       " 'serán',\n",
       " 'serás',\n",
       " 'seré',\n",
       " 'seréis',\n",
       " 'sería',\n",
       " 'seríais',\n",
       " 'seríamos',\n",
       " 'serían',\n",
       " 'serías',\n",
       " 'seáis',\n",
       " 'sido',\n",
       " 'siendo',\n",
       " 'sin',\n",
       " 'sobre',\n",
       " 'sois',\n",
       " 'somos',\n",
       " 'son',\n",
       " 'soy',\n",
       " 'su',\n",
       " 'sus',\n",
       " 'suya',\n",
       " 'suyas',\n",
       " 'suyo',\n",
       " 'suyos',\n",
       " 'sí',\n",
       " 'también',\n",
       " 'tanto',\n",
       " 'te',\n",
       " 'tendremos',\n",
       " 'tendrá',\n",
       " 'tendrán',\n",
       " 'tendrás',\n",
       " 'tendré',\n",
       " 'tendréis',\n",
       " 'tendría',\n",
       " 'tendríais',\n",
       " 'tendríamos',\n",
       " 'tendrían',\n",
       " 'tendrías',\n",
       " 'tened',\n",
       " 'tenemos',\n",
       " 'tenga',\n",
       " 'tengamos',\n",
       " 'tengan',\n",
       " 'tengas',\n",
       " 'tengo',\n",
       " 'tengáis',\n",
       " 'tenida',\n",
       " 'tenidas',\n",
       " 'tenido',\n",
       " 'tenidos',\n",
       " 'teniendo',\n",
       " 'tenéis',\n",
       " 'tenía',\n",
       " 'teníais',\n",
       " 'teníamos',\n",
       " 'tenían',\n",
       " 'tenías',\n",
       " 'ti',\n",
       " 'tiene',\n",
       " 'tienen',\n",
       " 'tienes',\n",
       " 'todo',\n",
       " 'todos',\n",
       " 'tu',\n",
       " 'tus',\n",
       " 'tuve',\n",
       " 'tuviera',\n",
       " 'tuvierais',\n",
       " 'tuvieran',\n",
       " 'tuvieras',\n",
       " 'tuvieron',\n",
       " 'tuviese',\n",
       " 'tuvieseis',\n",
       " 'tuviesen',\n",
       " 'tuvieses',\n",
       " 'tuvimos',\n",
       " 'tuviste',\n",
       " 'tuvisteis',\n",
       " 'tuviéramos',\n",
       " 'tuviésemos',\n",
       " 'tuvo',\n",
       " 'tuya',\n",
       " 'tuyas',\n",
       " 'tuyo',\n",
       " 'tuyos',\n",
       " 'tú',\n",
       " 'un',\n",
       " 'una',\n",
       " 'uno',\n",
       " 'unos',\n",
       " 'vosotras',\n",
       " 'vosotros',\n",
       " 'vuestra',\n",
       " 'vuestras',\n",
       " 'vuestro',\n",
       " 'vuestros',\n",
       " 'y',\n",
       " 'ya',\n",
       " 'yo',\n",
       " 'él',\n",
       " 'éramos']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stop_words('es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "empirical-lottery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>you've</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>your</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>yours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>yourself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>yourselves</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     stop_words\n",
       "0             a\n",
       "1         about\n",
       "2         above\n",
       "3         after\n",
       "4         again\n",
       "..          ...\n",
       "169      you've\n",
       "170        your\n",
       "171       yours\n",
       "172    yourself\n",
       "173  yourselves\n",
       "\n",
       "[174 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#as a list\n",
    "\n",
    "stop_words = get_stop_words('en')\n",
    "\n",
    "#as a DataFrame\n",
    "\n",
    "df_stop_words = pd.DataFrame({\n",
    "    'stop_words' : get_stop_words('en')\n",
    "})\n",
    "df_stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-edinburgh",
   "metadata": {},
   "source": [
    "We can `merge` both `Dataframe`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "enhanced-carnival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Book</th>\n",
       "      <th>Word</th>\n",
       "      <th>stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>boy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>who</td>\n",
       "      <td>who</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>lived</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mr</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77570</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>dudley</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77571</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>this</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77572</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>summer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77573</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77574</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>end</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77575 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Chapter  Book    Word stop_words\n",
       "0            1     1     the        the\n",
       "1            1     1     boy        NaN\n",
       "2            1     1     who        who\n",
       "3            1     1   lived        NaN\n",
       "4            1     1      mr        NaN\n",
       "...        ...   ...     ...        ...\n",
       "77570       17     1  dudley        NaN\n",
       "77571       17     1    this       this\n",
       "77572       17     1  summer        NaN\n",
       "77573       17     1     the        the\n",
       "77574       17     1     end        NaN\n",
       "\n",
       "[77575 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ps.merge(df_stop_words, how='left', left_on='Word', right_on='stop_words')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-instrumentation",
   "metadata": {},
   "source": [
    "and take just the `NaN` in `stop_words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "naval-committee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Book</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>lived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dursley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77566</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>lot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77568</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>fun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77570</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>dudley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77572</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77574</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42745 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Chapter  Book     Word\n",
       "1            1     1      boy\n",
       "3            1     1    lived\n",
       "4            1     1       mr\n",
       "6            1     1      mrs\n",
       "7            1     1  dursley\n",
       "...        ...   ...      ...\n",
       "77566       17     1      lot\n",
       "77568       17     1      fun\n",
       "77570       17     1   dudley\n",
       "77572       17     1   summer\n",
       "77574       17     1      end\n",
       "\n",
       "[42745 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = df_ps.merge(df_stop_words, how='left', left_on='Word', right_on='stop_words')\n",
    "\n",
    "merged[merged['stop_words'].isna()].drop('stop_words', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "upset-atlanta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1         True\n",
       "2        False\n",
       "3         True\n",
       "4         True\n",
       "         ...  \n",
       "77570     True\n",
       "77571    False\n",
       "77572     True\n",
       "77573    False\n",
       "77574     True\n",
       "Name: stop_words, Length: 77575, dtype: bool"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged['stop_words'].isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-plumbing",
   "metadata": {},
   "source": [
    "Or use a `lambda` function with `list` comprenhension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "nuclear-forth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dursley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42740</th>\n",
       "      <td>lot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42741</th>\n",
       "      <td>fun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42742</th>\n",
       "      <td>dudley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42743</th>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42744</th>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42745 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word\n",
       "0          boy\n",
       "1        lived\n",
       "2           mr\n",
       "3          mrs\n",
       "4      dursley\n",
       "...        ...\n",
       "42740      lot\n",
       "42741      fun\n",
       "42742   dudley\n",
       "42743   summer\n",
       "42744      end\n",
       "\n",
       "[42745 rows x 1 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ps[['Word']].apply(lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-leisure",
   "metadata": {},
   "source": [
    "You can also use `isin` and negate the mask to find values not in `df_stop_words`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "precious-championship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Book</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>lived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dursley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>lot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>fun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>dudley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42745 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Chapter  Book     Word\n",
       "0         1     1      boy\n",
       "0         1     1    lived\n",
       "0         1     1       mr\n",
       "0         1     1      mrs\n",
       "0         1     1  dursley\n",
       "..      ...   ...      ...\n",
       "16       17     1      lot\n",
       "16       17     1      fun\n",
       "16       17     1   dudley\n",
       "16       17     1   summer\n",
       "16       17     1      end\n",
       "\n",
       "[42745 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ps[~df_ps['Word'].isin(df_stop_words['stop_words'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-minority",
   "metadata": {},
   "source": [
    "**Task - 5 minutes**\n",
    "\n",
    "Find the most common words, not including stop words, in the book \"Chamber of Secrets\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-mandate",
   "metadata": {},
   "source": [
    "### Recap \n",
    "\n",
    "* Which function do you use to convert from text into words?\n",
    "\n",
    "**Solution:**  `unnest_tokens`\n",
    "\n",
    "\n",
    "* Which function do you use to count the number of words and arrange in order?\n",
    "\n",
    "**Solution:** \n",
    "`value_counts(..., sort = TRUE)`\n",
    "\n",
    "\n",
    "* How do you remove stopwords from a data frame?\n",
    "\n",
    "**Solution:** \n",
    "using `merge`, `lambda` or `isin`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-underwear",
   "metadata": {},
   "source": [
    "## Regular Expressions\n",
    "\n",
    "### Learning Outcomes\n",
    "\n",
    "* Know what a regular expression is\n",
    "* Be familiar with regular expression syntax\n",
    "* Use regular expressions to match patterns in text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-presentation",
   "metadata": {},
   "source": [
    "We've already seen some of the ways in which we can work with strings, including how we can include some special characters in our reports using Unicode. Now we're going to look at a way in which we can pick specific strings out of a collection based on the characters and symbols they contain.\n",
    "\n",
    "## What are regular expressions?\n",
    "\n",
    "A **regular expression** (usually abbreviated to a **regex**) is, fundamentally, just another type of string. We can use them to specify search terms or to validate data by making sure it fits a given pattern. We can also find and replace text in a more generic way than we can by using simple string methods, for example in order to redact email addresses or phone numbers.\n",
    "\n",
    "Regex is used in data analysis for a number of purposes - e.g. checking whether data is valid (does it follow a pattern of a valid email address, phone number or postcode), extracting parts of variables (e.g. maybe only want the first initial of a surname or the street name from your full address) and more generally it is used in text analysis - which we will come to in module 3.  \n",
    "\n",
    "## Matching patterns in text\n",
    "\n",
    "Let's take a look at some of the things we can do with regex. First up, we'll declare some strings to work with:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "limited-indiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_string = 'string a'\n",
    "strings = ['string a', 'string b', 'string c', 'string d', 'string e']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-initial",
   "metadata": {},
   "source": [
    "\n",
    "These strings all have something in common, but also have their differences. This is something you'll encounter fairly often when working with datasets, both text-based and numerical. Email addresses are a great example: they all contain the \"@\" symbol and all end in a similar way, eg. \".com\", but the other parts could be wildly different. Regex will enable us to find any email address hidden away in a dense block of text.\n",
    "\n",
    "## Matching Single Characters\n",
    "\n",
    "The easiest pattern we could try to match is a single alphanumeric character, and we can find some Python built-in functions to help us doing  it. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "documentary-panic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-husband",
   "metadata": {},
   "source": [
    "First we need to define the pattern we want to look for. To start with let's just look for the letter \"a\". Our pattern must be a string and is case-sensitive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "native-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'a'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-kenya",
   "metadata": {},
   "source": [
    "\n",
    "If we simply want to check if a pattern is present in a string we can use re's `search()` function to return a boolean value. We pass it two parameters: the string to check and the pattern to look for. As usual, the pipe operator will take care of the first 'data' argument for us.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "appropriate-distance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<re.Match object; span=(7, 8), match='a'>, None, None, None, None]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[re.search(pattern, x) for x in strings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "hawaiian-phase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a'], [], [], [], []]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[re.findall(pattern, x) for x in strings]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-sixth",
   "metadata": {},
   "source": [
    "If we simply want to check if a pattern is present in a string we can use pandas [`str.contains()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.contains.html) function to return a boolean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "baking-hammer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25549"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged['Word'].str.contains(pattern).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-omaha",
   "metadata": {},
   "source": [
    "If we want to test whether the start or the end of a string contains an element, we can use [`startswith`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.startswith.html) or [`endswith`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.endswith.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "instructional-young",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7622"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged['Word'].str.startswith(pattern).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "expected-subscriber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1901"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged['Word'].str.endswith(pattern).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-murder",
   "metadata": {},
   "source": [
    "If we want to find negative ocurrences we can simply use `~` to transform the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cardiac-diabetes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "         ... \n",
       "77570    True\n",
       "77571    True\n",
       "77572    True\n",
       "77573    True\n",
       "77574    True\n",
       "Name: Word, Length: 77575, dtype: bool"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~merged['Word'].str.endswith(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-cosmetic",
   "metadata": {},
   "source": [
    "## Matching multiple characters\n",
    "\n",
    "We don't need to limit ourselves to one character, we can check for many at once. The easiest use case is to look for a specific substring:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "respective-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'rry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "pursuant-chester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1418"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged['Word'].str.contains(pattern).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-butter",
   "metadata": {},
   "source": [
    "But, instead of looking for a substring, we can also look for a selection of characters. We do this by enclosing the characters we're looking for in square brackets (`[]`):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "seven-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '[abc]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "conventional-crest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32337"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged['Word'].str.contains(pattern).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-carroll",
   "metadata": {},
   "source": [
    "Note that there is no space between the characters, and that we still need to enclose the brackets in quotes. Here we're looking to match any string including the letters \"a\" **or** \"b\" **or** \"c\", (not the pattern \"abc\"). But what if we wanted to check for a bigger range of letters? Say from 'a' to 't' - do we need to manually type them all out? No! We can use a handy expression which checks for a range of characters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "stopped-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '[a-z]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "greater-rings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77551"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged['Word'].str.contains(pattern).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-observation",
   "metadata": {},
   "source": [
    "What happens if we change it to match capital letters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "frequent-anthropology",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '[A-Z]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ahead-board",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "77570    False\n",
       "77571    False\n",
       "77572    False\n",
       "77573    False\n",
       "77574    False\n",
       "Name: Word, Length: 77575, dtype: bool"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged['Word'].str.contains(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-costume",
   "metadata": {},
   "source": [
    "Nothing matches any more. We need to take care to use the correct casing when matching letters. If we wanted to match the whole alphabet we would combine the two cases using `[a-zA-Z]`. Or another option is you could cast your data to lower or upper case and then use the resulting case for regex matching.\n",
    "\n",
    "We can even be specific about how many occurrences of a character we're looking for. If we follow the character(s) with a number in braces (`{}`) we can be quite specific. Let's only match strings which have the letter \"i\" three times consecutively:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "simple-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '[i{3}]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fixed-undergraduate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19714"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged['Word'].str.contains(pattern).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-emperor",
   "metadata": {},
   "source": [
    "## Extracting matching substrings\n",
    "\n",
    "We've seen how we can find out if a string contains a regular expression or not, but how can we use what we find? We might be only be interestd in certain parts of our data and want to pull them out, or we might want to hide personal information in our dataset before we publish it. We can use regex for both of these.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "latter-option",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This string has an_address@email.com in it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This one has user.name@company.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Now we've got other_person_123@server.net and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@emailprovider.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data\n",
       "0         This string has an_address@email.com in it\n",
       "1               This one has user.name@company.co.uk\n",
       "2  Now we've got other_person_123@server.net and ...\n",
       "3                                 @emailprovider.com"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_data = pd.DataFrame({\n",
    "     'data': [\"This string has an_address@email.com in it\", \n",
    "            \"This one has user.name@company.co.uk\", \n",
    "            \"Now we've got other_person_123@server.net and my.name@runningoutofideas.com\",\n",
    "             \"@emailprovider.com\"\n",
    "             ]\n",
    "    \n",
    "})\n",
    "\n",
    "email_data\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-universal",
   "metadata": {},
   "source": [
    "### Extracting parts of a string\n",
    "\n",
    "we can use `str.extract` to extract groups from the strings in the given series object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "toxic-rainbow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  i\n",
       "1  i\n",
       "2  3\n",
       "3  i"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_data['data'].str.extract(pat = '([i{3}])')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-promotion",
   "metadata": {},
   "source": [
    "Well, we've found something at least. Our regex has matched the first lower case letter it found in each string, (`str.extract()` will pull out the first matching expression it finds and then stop, ignoring any other potential matches) which doesn't do us much good. We can be more specific though, and say that we want there to be an \"@\" symbol after those letters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "pleasant-century",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s@</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e@</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e@</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0   s@\n",
       "1   e@\n",
       "2   e@\n",
       "3  NaN"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_data['data'].str.extract(pat ='([a-z]@)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-confirmation",
   "metadata": {},
   "source": [
    "That's a bit better, but not much. We're now matching the symbol and the letter preceding it, but still only one letter. We need to capture all of the letters, but we don't know exactly how many there will be.\n",
    "\n",
    "If we're not sure about how many occurrences of a character there will be, we can use something called the **Kleene Star**. By adding a `*` after the character or group we want to match, we say \"match this expression if there are any number of occurences of these characters\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "mighty-registrar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@emailprovider.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "0                 NaN\n",
       "1                 NaN\n",
       "2                 NaN\n",
       "3  @emailprovider.com"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_data['data'].str.extract(pat ='([a-z]*@emailprovider.com)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-champion",
   "metadata": {},
   "source": [
    "Our expression has matched this string, but if we were checking for valid email addresses we would have wanted this to fail (since there's nothing before the \"@\"). This is the downside of the Kleene star -- it matches **any** number of occurrences, including none! If we want to make sure we have **at least one**, we use the `+` symbol:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "metric-finger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  NaN\n",
       "1  NaN\n",
       "2  NaN\n",
       "3  NaN"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_data['data'].str.extract(pat ='([a-z]+@emailprovider.com)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-counter",
   "metadata": {},
   "source": [
    "Much better.\n",
    "\n",
    "Let's incorporate what we've just seen into our own expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "occupied-newspaper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>address@</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name@</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>name@</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  address@\n",
       "1     name@\n",
       "2     name@\n",
       "3       NaN"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_data['data'].str.extract(pat ='([a-z]+@)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-dream",
   "metadata": {},
   "source": [
    "More progress! We're not just looking at letters before the \"@\" though, we've also got an address featuring numbers. We have to think about what comes after \"@\" too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "numerical-nebraska",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>address@email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name@company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123@server</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "0  address@email\n",
       "1   name@company\n",
       "2     123@server\n",
       "3            NaN"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_data['data'].str.extract(pat ='([a-z0-9]+@[a-z]+)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-editor",
   "metadata": {},
   "source": [
    "Almost there now. The final step is to include the punctuation marks which are vital to defining email addresses: \"_\" and \".\". We can include them in our expression just like any other character:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "helpful-mayor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>an_address@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user.name@company.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>other_person_123@server.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0\n",
       "0         an_address@email.com\n",
       "1      user.name@company.co.uk\n",
       "2  other_person_123@server.net\n",
       "3                          NaN"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_data['data'].str.extract(pat ='([a-z0-9._]+@[a-z.]+)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-greensboro",
   "metadata": {},
   "source": [
    "Success! We've pulled the email address out of each of our strings!\n",
    "\n",
    "Well, almost success... The last string had two email addresses in it, and we've only matched one. As we found earlier `str_extract()` will pull out the first matching expression it finds and then stop, ignoring any other potential matches. It has a partner in `str_extract_all()` which will find everything, though:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fabulous-harris",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>an_address@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>user.name@company.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>other_person_123@server.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my.name@runningoutofideas.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0\n",
       "  match                               \n",
       "0 0               an_address@email.com\n",
       "1 0            user.name@company.co.uk\n",
       "2 0        other_person_123@server.net\n",
       "  1      my.name@runningoutofideas.com"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_data['data'].str.extractall(pat ='([a-z0-9._]+@[a-z.]+)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-bulgarian",
   "metadata": {},
   "source": [
    "### Replacing Parts of a String\n",
    "\n",
    "We've looked at a way of finding any email addresses in a string, regardless of how long they are or where they sit in the string. That gives us a way to extract information from our datasets and analyse it. We may want to publish that dataset though, which means we probably don't want email addresses (or names, or phone numbers) left exposed in it. Instead of simply pulling the information out, we can replace it with something else.\n",
    "\n",
    "Let's say we want to replace all the email addresses in our strings above with \"REDACTED\". We can do it using the function `str_replace()`. It works in almost the same way as `str_extract()`, but this time takes another argument representing the string we want to use as a replacement:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "sudden-newfoundland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          This string has ANONYMOUS in it\n",
       "1                   This one has ANONYMOUS\n",
       "2    Now we've got ANONYMOUS and ANONYMOUS\n",
       "3                       @emailprovider.com\n",
       "Name: data, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_data['data'].str.replace('([a-z0-9._]+@[a-z.]+)', 'ANONYMOUS', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-turkey",
   "metadata": {},
   "source": [
    "Just like before, we replaced only the first matching string, but the 3rd element has 2 email addresses in it. Like before, we've got to fix it.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
